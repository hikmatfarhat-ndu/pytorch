{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTlGomZoqNrYLRxFXVX8zY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/pytorch/blob/main/convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/PyProf.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8THDaAi0X79_",
        "outputId": "3a8bad8b-3d2b-40aa-9a2a-32db85ad4148"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyProf'...\n",
            "remote: Enumerating objects: 1480, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 1480 (delta 51), reused 67 (delta 44), pack-reused 1390\u001b[K\n",
            "Receiving objects: 100% (1480/1480), 352.34 KiB | 19.57 MiB/s, done.\n",
            "Resolving deltas: 100% (1036/1036), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd PyProf;pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMqtI7xoYCVG",
        "outputId": "09824bd5-d3d1-4672-ffb4-6aa2762659df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/PyProf\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from nvidia-pyprof==3.11.0) (1.12.1+cu113)\n",
            "Collecting cxxfilt>=0.2.0\n",
            "  Downloading cxxfilt-0.3.0-py2.py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.7/dist-packages (from nvidia-pyprof==3.11.0) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from nvidia-pyprof==3.11.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->nvidia-pyprof==3.11.0) (4.1.1)\n",
            "Building wheels for collected packages: nvidia-pyprof\n",
            "  Building wheel for nvidia-pyprof (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyprof: filename=nvidia_pyprof-3.11.0-py3-none-any.whl size=86612 sha256=28bbab74beef72aacd13aecd68f76f61ad8f4589e8b17caf0ef929f96acfa088\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q208iqde/wheels/0b/e4/23/3a541864cf1d361dcf0c6fb513cee71a81c68d494e720da3e3\n",
            "Successfully built nvidia-pyprof\n",
            "Installing collected packages: cxxfilt, nvidia-pyprof\n",
            "Successfully installed cxxfilt-0.3.0 nvidia-pyprof-3.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "see https://github.com/NVIDIA/PyProf how to use"
      ],
      "metadata": {
        "id": "7Mqvta8agK3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "RC-B0vD5w5VH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision as vision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "ncY2kB4HxYJj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "6V4TKvYOEmVU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=transform)\n",
        "dataset_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=transform)\n",
        "loader_train=DataLoader(dataset_train,batch_size=512,shuffle=True,num_workers=4)\n",
        "loader_test=DataLoader(dataset_test,batch_size=512,shuffle=True)"
      ],
      "metadata": {
        "id": "czEw5fTvxdQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb38ad7-1550-4848-d58c-d6835964fd31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # input is (*,3,32,32)\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
        "    self.relu=nn.ReLU()\n",
        "    # input is (*,32,30,30)\n",
        "    self.pool1=nn.MaxPool2d(kernel_size=(2,2))\n",
        "    # input is (*,32,15,15)\n",
        "    self.conv2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
        "    # input is (*,64,13,13)\n",
        "    self.pool2=nn.MaxPool2d(kernel_size=(2,2))\n",
        "    # input is (*,64,6,6)\n",
        "    self.conv3=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
        "    # input is (*,64,4,4)\n",
        "    self.pool3=nn.MaxPool2d(kernel_size=(2,2))\n",
        "    # input is (*,64,2,2)\n",
        "    self.flatten=torch.flatten\n",
        "    # input is (*,64x2x2)\n",
        "    self.fc1=nn.Linear(in_features=2*2*64,out_features=64)\n",
        "    self.fc2=nn.Linear(in_features=64,out_features=10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.pool1(x)\n",
        "\n",
        "    x=self.conv2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.pool2(x)\n",
        "    \n",
        "    x=self.conv3(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.pool3(x)\n",
        "    \n",
        "    x=self.flatten(x,start_dim=1)\n",
        "    x=self.fc1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    return x\n",
        "    "
      ],
      "metadata": {
        "id": "n7c0dC1WTf8w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net().cuda()"
      ],
      "metadata": {
        "id": "f8gF3jH98jtT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "from torch.optim import SGD,Adam"
      ],
      "metadata": {
        "id": "zlL7ngED7718"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer=SGD(model.parameters(),lr=0.005)\n",
        "optimizer=Adam(model.parameters())"
      ],
      "metadata": {
        "id": "JRk2aJST8LrM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "from tqdm import tqdm\n",
        "for epoch in range(epochs):\n",
        "  loader_train=tqdm(loader_train)\n",
        "  for i, (imgs,labels) in enumerate(loader_train,0):\n",
        "    optimizer.zero_grad()\n",
        "    imgs=imgs.cuda()\n",
        "    labels=labels.cuda()\n",
        "    outputs=model(imgs)\n",
        "    loss=loss_fn(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss.item()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1aaOGae8n2N",
        "outputId": "0e3c7ad0-37dc-4be3-bbc2-8c355ce252bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:11<00:00,  8.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7584096193313599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:11<00:00,  8.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.388598084449768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3856546878814697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2780649662017822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1619975566864014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1550501585006714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.222307801246643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0854449272155762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.178902268409729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:09<00:00, 10.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.971398115158081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total=0\n",
        "correct=0\n",
        "for data in loader_test:\n",
        "  imgs,labels=data\n",
        "  imgs=imgs.cuda()\n",
        "  labels=labels.cuda()\n",
        "  outputs=model(imgs)\n",
        "  # the second return value is the index of the max i.e. argmax\n",
        "  _,predicted=torch.max(outputs.data,1)\n",
        "  total+=labels.size(0)\n",
        "  correct+=(predicted==labels).sum()\n"
      ],
      "metadata": {
        "id": "ReSk1t4C86ed"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBM21wZcBlcs",
        "outputId": "6212f59d-069e-4350-85fc-115a336c24e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6139, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  "
      ],
      "metadata": {
        "id": "8qzru2SMBotc"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}