{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/pytorch/blob/main/convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsIJu3J2Q-LX"
   },
   "source": [
    "# What you will learn\n",
    "1. Convolutional layers and the convolution operation\n",
    "1. Pooling layers\n",
    "1. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3yoP9bC2nH-"
   },
   "source": [
    "### CODE CELL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ncY2kB4HxYJj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as vision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD,Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIQwoLLmL1Ku"
   },
   "source": [
    "## Convolutional Network\n",
    "\n",
    "Convolutional neural network are very successfully in computer vision applications. They have the ability to progressively detect patterns in images and videos. Usually, the first few layers detect \"low level\" features such as lines and edges and, building on those, later layers detect more complicated features such as faces and objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgbNUPv3DuFd"
   },
   "source": [
    "### Convolution Operations\n",
    "We start with a simple example. Let I be an input image. Typically $I$ would be represented by a tensor of shape $(H,W,C)$ where $H$, $W$, and $C$ are the height, width, and color channel respectively. Therefore,  $I[h,w,c]$ refers to the value of channel $c$ in pixel $(h,w)$. Let $K$ be a filter with shape $(m,n)$ then the convolution operation produces the following tensor\n",
    "\\begin{align*}\n",
    "T_{i,j}=\\sum_c\\sum_{m,n}X_{i+m,j+n,c}*K_{m,n}\n",
    "\\end{align*}\n",
    "The above operation is illustrated in the example below. Click on the figures to see the sequence of operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "iKb-d5U7TVit",
    "outputId": "e91dc04c-8811-47c5-9d3c-d8f76e428ff5"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%HTML\n",
    "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vQBSo0SLsiigeXPOP4MGOS55ez9hvRT0xWocjs16K7U4JMTD1UnHXrNAu43qRo_GQ/embed?start=true&loop=true&delayms=3000\" frameborder=\"0\" width=\"500\" height=\"300\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNA6kJtKHckt"
   },
   "source": [
    "## Pooling\n",
    "Pooling replaces a region of the input with a \"summary\" statistic, usually the maximum. This makes the computation almost translation invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDZcLr1CMtJ_"
   },
   "source": [
    "### Pooling example\n",
    "\n",
    "In the example below, notice how the MaxPool2D picks the maximum from each 2x2 submatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5Uq1_TjM9wf",
    "outputId": "1beb5c3c-e0bb-4010-d4fc-0b49d54df0ad"
   },
   "outputs": [],
   "source": [
    "input=torch.tensor([[1,2,4,3],[5,6,8,7],[9,10,12,11],[13,14,16,2]]).float()\n",
    "# 1 sample, 1 channel, 4 height, 4 width\n",
    "input=input.reshape([1,1,4,4])\n",
    "output=nn.MaxPool2d(kernel_size=(2,2))(input)\n",
    "print(input.squeeze())\n",
    "print(output.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3NyN5gKOwS5"
   },
   "source": [
    "## Data\n",
    "The data is CIFAR10 with 50000 images for training and 10000 for testing. Each images has 3 channels and size 32x32.\n",
    "As we have done before we convert the PIL images to tensor and then normalize the values. Since there are 3 channels we need 3 values for the mean and 3 for the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6V4TKvYOEmVU"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0, 0, 0), (0.5, 0.5, 0.5))])\n",
    "dataset_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=transform)\n",
    "dataset_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=transform)\n",
    "loader_train=DataLoader(dataset_train,batch_size=64,shuffle=True,num_workers=2)\n",
    "loader_test=DataLoader(dataset_test,batch_size=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0kyAjE5PVrc"
   },
   "source": [
    "## Model\n",
    "\n",
    "- Our model uses a stack of convolutional and pooling layers. \n",
    "- The last two layers are fully connected with the size of the output of the last one is 10 = number of classes\n",
    "- Note that the output of convolutional layers a \"3-d\" objects so we need to \"flatten\" then before feeding them to the fully connected layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n7c0dC1WTf8w"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # input is (*,3,32,32)\n",
    "    self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
    "    self.relu=nn.ReLU()\n",
    "    # input is (*,32,30,30)\n",
    "    self.pool1=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,32,15,15)\n",
    "    self.conv2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "    # input is (*,64,13,13)\n",
    "    self.pool2=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,64,6,6)\n",
    "    self.conv3=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "    # input is (*,64,4,4)\n",
    "    self.pool3=nn.MaxPool2d(kernel_size=(2,2))\n",
    "    # input is (*,64,2,2)\n",
    "    self.flatten=nn.Flatten()\n",
    "    # input is (*,64x2x2)\n",
    "    self.fc1=nn.Linear(in_features=2*2*64,out_features=64)\n",
    "    self.fc2=nn.Linear(in_features=64,out_features=10)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x=self.conv1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool1(x)\n",
    "\n",
    "    x=self.conv2(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool2(x)\n",
    "    \n",
    "    x=self.conv3(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.pool3(x)\n",
    "    \n",
    "    x=self.flatten(x)\n",
    "    x=self.fc1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.fc2(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ayNL7ZjxB2Uu"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader,model):\n",
    "  total=len(dataloader.dataset.data)\n",
    "  correct=0\n",
    "  for data in dataloader:\n",
    "    imgs,labels=data\n",
    "    imgs=imgs.cuda()\n",
    "    labels=labels.cuda()\n",
    "    outputs=model(imgs)\n",
    "  # the second return value is the index of the max i.e. argmax\n",
    "    _,predicted=torch.max(outputs.data,1)\n",
    "    correct+=(predicted==labels).sum()\n",
    "  \n",
    "\n",
    "  return (correct/total).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v68yHDDn2_WP"
   },
   "source": [
    "Instantiate the model, the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f8gF3jH98jtT"
   },
   "outputs": [],
   "source": [
    "model=Net().cuda()\n",
    "optimizer=Adam(model.parameters())\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-h6lTtHKlMM"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1aaOGae8n2N",
    "outputId": "bc130cb1-3beb-467c-f7a9-b1058cee3809"
   },
   "outputs": [],
   "source": [
    "epochs=3\n",
    "from tqdm import tqdm\n",
    "for epoch in range(epochs):\n",
    "  loop=tqdm(loader_train)\n",
    "  loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "  for (imgs,labels) in loop:\n",
    "    optimizer.zero_grad()\n",
    "    imgs=imgs.cuda()\n",
    "    labels=labels.cuda()\n",
    "    outputs=model(imgs)\n",
    "    loss=loss_fn(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "   \n",
    "  acc=get_accuracy(loader_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJpbDV7pdXRK"
   },
   "source": [
    "# Accuracy and confusion matrix\n",
    "\n",
    "One would like to measure the accuracy of the model at the end of the run. As important, to get an idea which class is more/less accurately predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXxIMoblYRwO",
    "outputId": "04ac42fe-406a-47f7-d20c-b7cd6873d3df"
   },
   "outputs": [],
   "source": [
    "!pip install torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "conmat=ConfusionMatrix(task=\"multiclass\",num_classes=10)\n",
    "conmat=conmat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ReSk1t4C86ed"
   },
   "outputs": [],
   "source": [
    "total=0\n",
    "correct=0\n",
    "for data in loader_test:\n",
    "  imgs,labels=data\n",
    "  imgs=imgs.cuda()\n",
    "  labels=labels.cuda()\n",
    "  outputs=model(imgs)\n",
    "  # the second return value is the index of the max i.e. argmax\n",
    "  _,predicted=torch.max(outputs.data,1)\n",
    "  correct+=(predicted==labels).sum()\n",
    "  total+=labels.size()[0]\n",
    "  conmat.update(predicted,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBM21wZcBlcs",
    "outputId": "5b93855c-8c08-4882-ce1c-8aae340ad3fc"
   },
   "outputs": [],
   "source": [
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqxWwZGD3czw"
   },
   "source": [
    "Visualize the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "zWo0YjDdXrkd",
    "outputId": "684ca19f-4c3d-40b1-d50f-8c10c288c6f0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "x=conmat.compute().cpu().numpy()\n",
    "plt.figure(figsize=(10,7))\n",
    "sb.heatmap(x,xticklabels=dataset_train.classes,yticklabels=dataset_train.classes,annot=True,fmt=\".0f\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMeyaRojXCEOcgKW8I0/Y0k",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
