{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWXbPuMZKGWEF+9xsBpR2j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/pytorch/blob/main/custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IF1cj4oHQy6F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision as vision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/emanhamed/Houses-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEZLbxXLRhDQ",
        "outputId": "9361844e-d6e7-465a-b006-2ce4dad703b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Houses-dataset' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Houses-dataset/Houses Dataset/HousesInfo.txt\",header=None,delim_whitespace=True,\n",
        "               names=[\"bedrooms\",\"bathrooms\",\"size\",\"zipcode\",\"price\"])"
      ],
      "metadata": {
        "id": "JB3jj_iWR9AZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove all entries with zipcodes occuring less than 20 times"
      ],
      "metadata": {
        "id": "lPa19JSa2tlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanData(df):\n",
        "    # compute the number of entries per zipcode\n",
        "    zipcodes=df['zipcode'].value_counts().keys().tolist()\n",
        "    counts=df['zipcode'].value_counts().tolist()\n",
        "    #discard all zipcodes ocurring less than 20 times\n",
        "    for count,zipcode in zip(counts,zipcodes):\n",
        "      if count<20:\n",
        "        idx=df[df['zipcode']==zipcode].index\n",
        "        df.drop(idx,inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "O_YDMNrDjKPQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=cleanData(df)"
      ],
      "metadata": {
        "id": "JEmjuzSwjMJf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import shutil\n",
        "from_prefix=\"Houses-dataset/Houses Dataset/\"\n",
        "to_prefix=\"images/\"\n",
        "suffix=\"_frontal.jpg\"\n",
        "!mkdir -p images\n",
        "for newidx,oldidx in enumerate(df.index.tolist()):\n",
        "  oldname=from_prefix+str(oldidx)+suffix\n",
        "  newname=to_prefix+str(newidx)+suffix\n",
        "  #print(\"moving from %s to %s\"%(oldname,newname))\n",
        "  shutil.copy(oldname,newname)\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "6-MUq6QILcov",
        "outputId": "7d4d8dc6-cc80-42b6-a41e-f00aa84c6dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport shutil\\nfrom_prefix=\"Houses-dataset/Houses Dataset/\"\\nto_prefix=\"images/\"\\nsuffix=\"_frontal.jpg\"\\n!mkdir -p images\\nfor newidx,oldidx in enumerate(df.index.tolist()):\\n  oldname=from_prefix+str(oldidx)+suffix\\n  newname=to_prefix+str(newidx)+suffix\\n  #print(\"moving from %s to %s\"%(oldname,newname))\\n  shutil.copy(oldname,newname)\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#randomize the dataframe\n",
        "ran_dataset=dataset.sample(len(dataset))"
      ],
      "metadata": {
        "id": "3A-UNEYyJbDY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset has 384 entries. Choose 310 for training and 74 for testing\n",
        "train_dataset=ran_dataset[0:310]\n",
        "test_dataset=ran_dataset[310:len(dataset)]\n",
        "train_dataset.to_csv(\"train.csv\",index_label=\"index\")\n",
        "test_dataset.to_csv(\"test.csv\",index_label=\"index\")"
      ],
      "metadata": {
        "id": "unzAxt0nHUGK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_image\n",
        "import os\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,csvFile,imgDir):\n",
        "    self.imgDir=imgDir\n",
        "    dataset=pd.read_csv(csvFile)\n",
        "    dummy=pd.get_dummies(dataset['zipcode'])\n",
        "    price=dataset['price']\n",
        "    size=dataset['size']\n",
        "    self.max_size=size.max()\n",
        "    self.max_price=price.max()\n",
        "    size=size/self.max_size\n",
        "    price=price/self.max_price\n",
        "    df=dataset.drop(['size','price','zipcode'],axis=1)\n",
        "    self.data=pd.concat([df,size,dummy,price],axis=1)\n",
        "    self.resize=vision.transforms.Resize((48,48))\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    #\n",
        "    img_idx=self.data.iloc[idx,0]\n",
        "    # the images were labelled starting at 1. Pandas starts at 0\n",
        "    path=os.path.join(self.imgDir,str(img_idx+1)+\"_frontal.jpg\")\n",
        "    img=read_image(path)\n",
        "    img=self.resize(img)\n",
        "    return self.data.iloc[idx,1:-1].to_numpy(dtype=np.float32),img,np.float32(self.data.iloc[idx,-1])"
      ],
      "metadata": {
        "id": "Uuj8m0exRFgB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=CustomDataset(\"train.csv\",\"Houses-dataset/Houses Dataset/\")\n",
        "test_dataset=CustomDataset(\"test.csv\",\"Houses-dataset/Houses Dataset/\")"
      ],
      "metadata": {
        "id": "d8sNvU2NCmEI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
        "test_loader=DataLoader(test_dataset,batch_size=1,shuffle=False)"
      ],
      "metadata": {
        "id": "NvvvxTTe0I_y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itr=iter(train_loader)\n",
        "data=next(itr)"
      ],
      "metadata": {
        "id": "IDtrS2vF76aa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.relu=nn.ReLU() \n",
        "    self.fc1=nn.Linear(in_features=11,out_features=32)\n",
        "    self.fc2=nn.Linear(in_features=32,out_features=16)\n",
        "    self.fc3=nn.Linear(in_features=16,out_features=1)\n",
        "  def forward(self,x):\n",
        "    x=self.fc1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "K6VOQQ1dHxZ-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD,Adam\n",
        "from torch.nn import MSELoss,L1Loss\n",
        "\n",
        "model=Net()\n",
        "#optimizer=SGD(model.parameters(),lr=0.001)\n",
        "optimizer=Adam(model.parameters())\n",
        "#loss_fn=MSELoss()\n",
        "loss_fn=L1Loss()\n",
        "epochs=50\n",
        "for epoch in range(epochs):\n",
        "  for input,img,price in train_loader:\n",
        "    output=model(input)\n",
        "    loss=loss_fn(output.squeeze(),price)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "lqu_RAVUM9t7",
        "outputId": "df0bc80d-2d41-4dfd-b2e2-0f85e6bf8d0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0531, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.1840, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0283, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0097, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0224, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0217, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0140, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0272, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0179, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0826, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0084, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0443, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0158, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0241, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0201, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0051, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0162, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0170, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0167, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0275, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0122, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0206, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0260, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0162, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0166, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0221, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0201, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0130, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0218, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0718, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0144, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0220, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0165, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0235, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0697, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0102, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0779, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0113, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0214, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0258, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0166, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0130, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0043, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0054, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0178, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0220, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0092, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0164, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0165, grad_fn=<L1LossBackward0>)\n",
            "tensor(0.0215, grad_fn=<L1LossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itr=iter(test_loader)\n",
        "max_test=test_dataset.max_price\n",
        "max_train=train_dataset.max_price\n",
        "print(max_test,max_train)\n"
      ],
      "metadata": {
        "id": "8kZsbOJNMtUI",
        "outputId": "a7f78bdf-4ee9-4263-feb3-ed9f6d25e087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2200000 5858000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input,img,price=next(itr)\n",
        "print(price.item()*max_test)\n",
        "output=model(input)\n",
        "output.item()*max_train"
      ],
      "metadata": {
        "id": "rP83aIx7NmFa",
        "outputId": "a18131f1-884b-4169-a827-9d1ca7c9092a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "628999.9902248383\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "554011.4190131426"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total=0.0\n",
        "total2=0.0\n",
        "count=0\n",
        "max_test=test_dataset.max_price\n",
        "max_train=train_dataset.max_price\n",
        "for _,(input,img,price) in enumerate(test_loader):\n",
        "  count+=1\n",
        "  output=model(input)\n",
        "  #print(torch.abs(price*max_test-output.item()*max_train)/(price*max_test))\n",
        "  abs=(torch.abs(output.item()*max_train-price*max_test)/(price*max_test)).squeeze()\n",
        "  total+=abs"
      ],
      "metadata": {
        "id": "_K0NHnUO-tej"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total/count)"
      ],
      "metadata": {
        "id": "fCnxPl41Mg8F",
        "outputId": "64319653-857a-4308-9b08-eeba59f2261a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2822)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4KSfTT2NUxX"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}